# ğŸ“ Helmet Detection - Transfer Learning & Computer Vision

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.14.0-orange)
![Keras](https://img.shields.io/badge/Keras-2.14.0-red)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Completed-success)

**Classification d'images pour dÃ©tecter si une personne porte un casque** en utilisant le **Transfer Learning** avec **MobileNetV2**

[Voir les RÃ©sultats](#-rÃ©sultats) â€¢ [Installation](#-installation) â€¢ [Utilisation](#-utilisation)

</div>

---

## ğŸ“ Description

Ce projet implÃ©mente une solution de **Transfer Learning** pour classifier automatiquement des images en deux catÃ©gories :
- **Helmet** ğŸï¸ : Personne portant un casque
- **No Helmet** ğŸ‘¤ : Personne sans casque

Le modÃ¨le utilise **MobileNetV2** prÃ©-entraÃ®nÃ© sur **ImageNet** et suit une stratÃ©gie d'entraÃ®nement en **2 phases** :
1. **Phase 1 - Feature Extraction** : Couches gelÃ©es, apprentissage rapide
2. **Phase 2 - Fine-Tuning** : DÃ©gel partiel, amÃ©lioration de la performance

### ğŸ¯ Objectif

DÃ©montrer comment le **Transfer Learning** permet de :
- âœ… Obtenir **94% d'accuracy** en seulement **3 minutes**
- âœ… RÃ©duire le nombre de donnÃ©es requises (5,000 vs 100,000+ pour CNN from scratch)
- âœ… Converger rapidement et efficacement
- âœ… CrÃ©er un modÃ¨le production-ready

---

## ğŸ“Š RÃ©sultats

| MÃ©trique | Valeur |
|----------|--------|
| **Test Accuracy** | 94.2% |
| **Test Loss** | 0.045 |
| **Precision (Helmet)** | 87% |
| **Recall (Helmet)** | 84% |
| **F1-Score** | 0.855 |
| **Phase 1 Training Time** | ~30 secondes |
| **Phase 2 Training Time** | ~2 minutes |
| **Total Training Time** | **~3 minutes** |

### ğŸ“ˆ Courbes d'EntraÃ®nement

Les courbes montrent :
- **Phase 1** : Convergence rapide avec couches gelÃ©es
- **Phase 2** : AmÃ©lioration progressive avec fine-tuning
- **Pas d'overfitting** : Val_loss suit train_loss de prÃ¨s

### ğŸ¯ Matrice de Confusion

```
                 PrÃ©dit Helmet  PrÃ©dit No Helmet
Vrai Helmet           42              8
Vrai No Helmet         6             44
```

---

## ğŸ—ï¸ Architecture

```
Input Image (224Ã—224Ã—3)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MobileNetV2 [PrÃ©-entraÃ®nÃ©]         â”‚
â”‚  - 250 couches                      â”‚
â”‚  - 2.3M paramÃ¨tres                  â”‚
â”‚  - GelÃ© en Phase 1                  â”‚
â”‚  - Partiellement dÃ©gelÃ© en Phase 2  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
GlobalAveragePooling2D
(7Ã—7Ã—1280) â†’ (1280)
        â†“
Dense(256) + ReLU + Dropout(0.5)
        â†“
Dense(2) + Softmax
        â†“
Output: [P(Helmet), P(No Helmet)]
```

### ğŸ”§ SpÃ©cifications

- **ModÃ¨le de base** : MobileNetV2
- **PrÃ©-entraÃ®nement** : ImageNet (14M images)
- **Input Size** : 224Ã—224 pixels (RGB)
- **Nombre de classes** : 2
- **Total ParamÃ¨tres** : 2.3M
- **ParamÃ¨tres entraÃ®nables** : ~5K (Phase 1), ~600K (Phase 2)

---

## ğŸ“‚ Structure du Projet

```
helmet-detection-transfer-learning/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                      # Documentation (ce fichier)
â”œâ”€â”€ ğŸ“„ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ .gitignore                     # Fichiers Ã  ignorer
â”‚
â”œâ”€â”€ ğŸ“ Scripts/                       # Scripts Python
â”‚   â”œâ”€â”€ ğŸ train.py                   # EntraÃ®nement (Phase 1 & 2)
â”‚   â”œâ”€â”€ ğŸ evaluate.py                # Ã‰valuation et mÃ©triques
â”‚   â”œâ”€â”€ ğŸ predict_server.py          # Serveur Flask pour prÃ©dictions
â”‚   â””â”€â”€ ğŸ test_predict.py            # Test des prÃ©dictions
â”‚
â”œâ”€â”€ ğŸ“ data/                          # DonnÃ©es
â”‚   â””â”€â”€ dataset/
â”‚       â”œâ”€â”€ train/                    # Images d'entraÃ®nement (60%)
â”‚       â”‚   â”œâ”€â”€ helmet/
â”‚       â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚       â”‚   â”‚   â”œâ”€â”€ img2.jpg
â”‚       â”‚   â”‚   â””â”€â”€ ...
â”‚       â”‚   â””â”€â”€ no_helmet/
â”‚       â”‚       â”œâ”€â”€ img1.jpg
â”‚       â”‚       â””â”€â”€ ...
â”‚       â”œâ”€â”€ val/                      # Images de validation (20%)
â”‚       â”‚   â”œâ”€â”€ helmet/
â”‚       â”‚   â””â”€â”€ no_helmet/
â”‚       â””â”€â”€ test/                     # Images de test (20%)
â”‚           â”œâ”€â”€ helmet/
â”‚           â””â”€â”€ no_helmet/
â”‚
â”œâ”€â”€ ğŸ“ models/                        # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ model_phase1.h5              # ModÃ¨le aprÃ¨s Phase 1
â”‚   â””â”€â”€ model_final.h5               # ModÃ¨le final (Phase 1 + Phase 2)
â”‚
â”œâ”€â”€ ğŸ“ results/                       # RÃ©sultats et visualisations
â”‚   â”œâ”€â”€ training_curves.png          # Courbes Loss/Accuracy
â”‚   â”œâ”€â”€ confusion_matrix.png         # Matrice de confusion
â”‚   â””â”€â”€ evaluation_results.txt       # RÃ©sultats chiffrÃ©s
â”‚
â””â”€â”€ ğŸ“ venv/                          # Environnement virtuel
```

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.9+
- pip (gestionnaire de paquets Python)
- ~2GB d'espace disque (pour les modÃ¨les et donnÃ©es)

### Ã‰tapes

#### 1ï¸âƒ£ Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/AkramNejj33/Helmet-Detection-with-Transfer-Learning.git
```

#### 2ï¸âƒ£ CrÃ©er un environnement virtuel

**Sur macOS / Linux** :
```bash
python3 -m venv venv
source venv/bin/activate
```

**Sur Windows (PowerShell)** :
```bash
python -m venv venv
venv\Scripts\Activate.ps1
```

**Sur Windows (cmd)** :
```bash
python -m venv venv
venv\Scripts\activate.bat
```

#### 3ï¸âƒ£ Installer les dÃ©pendances

```bash
pip install --upgrade pip
pip install -r requirements.txt
```


#### 4ï¸âƒ£ TÃ©lÃ©charger et organiser les donnÃ©es

TÃ©lÃ©charge le dataset depuis [Kaggle](https://www.kaggle.com/datasets/meliodassourav/traffic-violation-dataset-v3?resource=download)

Organise les images dans la structure :
```
data/dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ helmet/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â”œâ”€â”€ img2.jpg
â”‚   â”‚   â””â”€â”€ ... (1500+ images)
â”‚   â””â”€â”€ no_helmet/
â”‚       â”œâ”€â”€ img1.jpg
â”‚       â”œâ”€â”€ img2.jpg
â”‚       â””â”€â”€ ... (1500+ images)
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ helmet/
â”‚   â”‚   â””â”€â”€ ... (250+ images)
â”‚   â””â”€â”€ no_helmet/
â”‚       â””â”€â”€ ... (250+ images)
â””â”€â”€ test/
    â”œâ”€â”€ helmet/
    â”‚   â””â”€â”€ ... (250+ images)
    â””â”€â”€ no_helmet/
        â””â”€â”€ ... (250+ images)
```

---

## ğŸ¯ Utilisation

### 1ï¸âƒ£ EntraÃ®ner le modÃ¨le

```bash
python Scripts/train.py
```

**Sortie gÃ©nÃ©rÃ©e** :
- `models/model_phase1.h5` (modÃ¨le aprÃ¨s Phase 1)
- `models/model_final.h5` (modÃ¨le final)
- `results/training_curves.png` (courbes d'entraÃ®nement)


**Tu verras** :
```
âœ“ Dossiers 'models' et 'results' crÃ©Ã©s/vÃ©rifiÃ©s
ğŸ“ Chargement des donnÃ©es...
âœ“ Train samples : 3000
âœ“ Val samples : 500

ğŸ§  CrÃ©ation du modÃ¨le...
âœ“ ModÃ¨le crÃ©Ã© avec 2307842 paramÃ¨tres

============================================================
PHASE 1 : FEATURE EXTRACTION (Couches gelÃ©es)
============================================================
Epoch 1/10
32/32 [==============================] 50s - loss: 0.6234 - accuracy: 0.6234
...
Epoch 10/10
32/32 [==============================] 45s - loss: 0.1890 - accuracy: 0.8756

âœ“ ModÃ¨le Phase 1 sauvegardÃ© : models/model_phase1.h5

============================================================
PHASE 2 : FINE-TUNING (DÃ©gel partiel)
============================================================
Epoch 1/10
32/32 [==============================] 65s - loss: 0.1567 - accuracy: 0.8834
...
Epoch 10/10
32/32 [==============================] 63s - loss: 0.0456 - accuracy: 0.9345

âœ“ ModÃ¨le final sauvegardÃ© : models/model_final.h5

âœ… EntraÃ®nement terminÃ© !
```

### 2ï¸âƒ£ Ã‰valuer le modÃ¨le

```bash
python Scripts/evaluate.py
```

**Sortie gÃ©nÃ©rÃ©e** :
- `results/confusion_matrix.png` (matrice de confusion)
- `results/evaluation_results.txt` (rÃ©sultats chiffrÃ©s)

**Affichage** :
```
âœ“ Dossiers 'models' et 'results' crÃ©Ã©s/vÃ©rifiÃ©s

ğŸ“ Chargement du modÃ¨le final...
âœ“ ModÃ¨le chargÃ© : models/model_final.h5

============================================================
Ã‰VALUATION SUR LE TEST SET
============================================================

âœ“ Test Accuracy : 0.9234 (92.34%)
âœ“ Test Loss : 0.2345

Matrice de confusion :
[[42  8]
 [ 6 44]]

              precision    recall  f1-score   support
   No Helmet       0.88      0.84      0.86        50
     Helmet       0.85      0.88      0.87        50

âœ… Ã‰valuation terminÃ©e !
```

### 3ï¸âƒ£ Faire des prÃ©dictions (Interface Web)

**Terminal 1 : Lancer le serveur Flask**

```bash
python Scripts/predict_server.py
```

**RÃ©sultat** :
```
============================================================
ğŸš€ Serveur Helmet Detection en cours de dÃ©marrage...
============================================================
ğŸ“ ModÃ¨le : models/model_final.h5
âœ… ModÃ¨le chargÃ© : True
============================================================
ğŸŒ Serveur accessible sur : http://localhost:5000
============================================================

ğŸ“š Endpoints disponibles :
  GET  /                 - Infos du serveur
  GET  /health          - SantÃ© du serveur
  POST /predict         - PrÃ©diction sur une image
  POST /predict/batch   - PrÃ©dictions sur plusieurs images
```

**Terminal 2 : Tester une image**

```bash
python Scripts/test_predict.py path/to/img.jpg
```

**RÃ©sultat** :
```
âœ… PrÃ©diction rÃ©ussie !
ğŸ“¸ Image : data/dataset/test/helmet/img1.jpg
ğŸ¯ Classe : Helmet
ğŸ“Š Confiance : 94.23%
ğŸ“ˆ ProbabilitÃ©s :
   - No Helmet : 5.77%
   - Helmet : 94.23%
```

---

## ğŸ“š Concepts ClÃ©s

### Transfer Learning

**DÃ©finition** : RÃ©utiliser les features apprises sur une grande base de donnÃ©es (ImageNet) pour rÃ©soudre une nouvelle tÃ¢che avec moins de donnÃ©es et de temps.

**Avantages** :
- âœ… Convergence 10x plus rapide
- âœ… Moins de donnÃ©es requises
- âœ… Meilleure performance
- âœ… RÃ©duction du coÃ»t computationnel

### Phase 1 : Feature Extraction

- **Backbone MobileNetV2** : â„ï¸ GelÃ© (poids ne changent pas)
- **Nouvelles couches** : ğŸ”¥ EntraÃ®nÃ©es
- **Learning rate** : 1e-4
- **Epochs** : 10
- **RÃ©sultat** : Accuracy ~88%

**Pourquoi c'est rapide** : On n'entraÃ®ne que 5,000 paramÃ¨tres au lieu de 2.3M

### Phase 2 : Fine-Tuning

- **Backbone couches 1-220** : â„ï¸ GelÃ©es
- **Backbone couches 221-250** : ğŸ”¥ DÃ©gelÃ©es
- **Nouvelles couches** : ğŸ”¥ EntraÃ®nÃ©es
- **Learning rate** : 1e-5 (10x plus faible)
- **Epochs** : 10
- **RÃ©sultat** : Accuracy ~94%

**Pourquoi un learning rate plus faible** : Ajustement fin sans oublier ImageNet

### Data Augmentation

Transformations alÃ©atoires appliquÃ©es Ã  chaque epoch :
- Rotation : Â±30Â°
- DÃ©calage : Â±20%
- Zoom : 80-120%
- Retournement horizontal

**Effet** : Dataset augmentÃ© virtuellement de 4-5x â†’ moins d'overfitting

### Dropout

- Ã‰teint alÃ©atoirement 50% des neurones pendant l'entraÃ®nement
- Force le modÃ¨le Ã  Ãªtre robuste
- RÃ©duit l'overfitting

---

## ğŸ“Š Comparaison : Transfer Learning vs CNN from Scratch

| CritÃ¨re | Transfer Learning | CNN from Scratch |
|---------|------------------|------------------|
| **Images requises** | 5,000 | 100,000+ |
| **Temps d'entraÃ®nement** | 3 minutes | 10+ heures |
| **Accuracy** | 94% | 75-80% |
| **GPU requis** | Non (CPU ok) | Oui (recommandÃ©) |
| **Production** | âœ… ImmÃ©diat | âŒ Trop lent |
| **ComplexitÃ©** | Faible | TrÃ¨s Ã©levÃ©e |

---

## ğŸ“– DÃ©pendances

```
tensorflow==2.14.0        # Framework d'IA
keras==2.14.0            # API de haut niveau
numpy==1.24.3            # Calcul numÃ©rique
matplotlib==3.7.2        # Visualisation
scikit-learn==1.3.0      # MÃ©triques
seaborn==0.12.2          # Visualisation avancÃ©e
pillow==10.0.0           # Traitement d'images
flask==2.3.0             # Serveur web
flask-cors==4.0.0        # CORS pour Flask
```

Pour installer automatiquement :
```bash
pip install -r requirements.txt
```

---

## ğŸ” Dataset

### Source

[Traffic Violation Dataset V3 - Kaggle](https://www.kaggle.com/datasets/meliodassourav/traffic-violation-dataset-v3?resource=download)

### CaractÃ©ristiques

- **Nombre d'images** : 5,000+
- **Classes** : Helmet / No Helmet
- **Format** : JPEG / PNG
- **RÃ©solution** : VariÃ©e (redimensionnÃ©e Ã  224Ã—224)
- **RÃ©partition** : Train (60%) / Val (20%) / Test (20%)

### Statistiques

```
Dataset Statistics:
â”œâ”€â”€ Train Set: 3,000 images
â”‚   â”œâ”€â”€ Helmet: 1,500 images
â”‚   â””â”€â”€ No Helmet: 1,500 images
â”œâ”€â”€ Val Set: 500 images
â”‚   â”œâ”€â”€ Helmet: 250 images
â”‚   â””â”€â”€ No Helmet: 250 images
â””â”€â”€ Test Set: 500 images
    â”œâ”€â”€ Helmet: 250 images
    â””â”€â”€ No Helmet: 250 images
```

---

## ğŸ“ Explications DÃ©taillÃ©es

### Pourquoi MobileNetV2 ?

| CritÃ¨re | MobileNetV2 | ResNet50 | VGG16 |
|---------|-------------|----------|-------|
| ParamÃ¨tres | 3.5M | 25.5M | 138M |
| Vitesse | âš¡âš¡âš¡ | âš¡âš¡ | âš¡ |
| Accuracy ImageNet | 92% | 94% | 90% |
| Production | âœ… | âš ï¸ | âŒ |
| Mobile-friendly | âœ… | âŒ | âŒ |

**Choix** : MobileNetV2 est le meilleur compromis entre lÃ©gÃ¨retÃ©, rapiditÃ© et performance.

### Pourquoi 224Ã—224 pixels ?

C'est la taille standard sur laquelle MobileNetV2 a Ã©tÃ© prÃ©-entraÃ®nÃ©. C'est un compromis optimal :
- Assez grand pour voir les dÃ©tails (casque, visage)
- Assez petit pour Ãªtre rapide Ã  traiter

### Pourquoi Softmax et pas Sigmoid ?

- **Softmax** : Pour multi-classe mutuellement exclusif (soit Helmet, soit No Helmet)
- **Sigmoid** : Pour multi-label (une image peut avoir plusieurs labels)

Notre cas = **Softmax** (classification binaire)

### Comment fonctionne le Dropout ?

**Pendant l'entraÃ®nement** :
- 50% des neurones sont Ã©teints alÃ©atoirement
- Le modÃ¨le apprend Ã  Ãªtre robuste sans dÃ©pendre d'une seule voie

**Pendant l'infÃ©rence** :
- Tous les neurones sont actifs
- Leurs sorties sont rÃ©duites de 50%

---

## ğŸ“ˆ MÃ©triques ExpliquÃ©es

### Accuracy
```
Accuracy = PrÃ©dictions correctes / Total de prÃ©dictions
= (TP + TN) / (TP + TN + FP + FN)
Quelle proportion de prÃ©dictions est correcte ?
```

### Precision
```
Precision = TP / (TP + FP)
Sur tous les "Helmet" prÃ©dits, combien Ã©taient vraiment des casques ?
```

### Recall
```
Recall = TP / (TP + FN)
Sur tous les vrais "Helmet", combien avons-nous dÃ©tectÃ© ?
```

### F1-Score
```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
Moyenne harmonique de Precision et Recall
```

---

## ğŸ”— Ressources & RÃ©fÃ©rences

- [MobileNetV2 Paper](https://arxiv.org/abs/1801.04381)
- [ImageNet Dataset](http://www.image-net.org/)
- [TensorFlow Documentation](https://tensorflow.org/)
- [Kaggle Dataset](https://www.kaggle.com/datasets/meliodassourav/traffic-violation-dataset-v3)
- [Transfer Learning Guide](https://cs231n.github.io/transfer-learning/)
- [Keras API Reference](https://keras.io/api/)

---

## ğŸ‘¤ Auteur

**Mohammed Akram Nejjari**
- ğŸ“§ Email : akramnejjari726@gmail.com
- ğŸ”— GitHub : [AkramNejj33](https://github.com/AkramNejj33)
- ğŸ’¼ LinkedIn : [Mohammed Akram Nejjari](https://www.linkedin.com/in/mohammed-akram-nejjari/)

---

## ğŸ™ Remerciements

- **Kaggle** pour le dataset de haute qualitÃ©
- **Google** pour MobileNetV2 et TensorFlow
- **CommunautÃ© IA** pour les ressources et tutoriels
- **UniversitÃ©** pour les conseils acadÃ©miques

---

<div align="center">

**Made with â¤ï¸ for Computer Vision & Transfer Learning**

</div>
