# ğŸ“ Helmet Detection - Transfer Learning & Computer Vision

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.14.0-orange)
![Keras](https://img.shields.io/badge/Keras-2.14.0-red)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Completed-success)

**Classification d'images pour dÃ©tecter si une personne porte un casque** en utilisant le **Transfer Learning** avec **MobileNetV2**

[Voir les RÃ©sultats](#-rÃ©sultats) â€¢ [Installation](#-installation) â€¢ [Utilisation](#-utilisation)

</div>

---

## ğŸ“ Description

Ce projet implÃ©mente une solution de **Transfer Learning** pour classifier automatiquement des images en deux catÃ©gories :
- **Helmet** ğŸï¸ : Personne portant un casque
- **No Helmet** ğŸ‘¤ : Personne sans casque

Le modÃ¨le utilise **MobileNetV2** prÃ©-entraÃ®nÃ© sur **ImageNet** et suit une stratÃ©gie d'entraÃ®nement en **2 phases** :
1. **Phase 1 - Feature Extraction** : Couches gelÃ©es, apprentissage rapide
2. **Phase 2 - Fine-Tuning** : DÃ©gel partiel, amÃ©lioration de la performance

### ğŸ¯ Objectif

DÃ©montrer comment le **Transfer Learning** permet de :
- âœ… Obtenir **94% d'accuracy** en seulement **3 minutes**
- âœ… RÃ©duire le nombre de donnÃ©es requises (5,000 vs 100,000+ pour CNN from scratch)
- âœ… Converger rapidement et efficacement
- âœ… CrÃ©er un modÃ¨le production-ready

---

## ğŸ“Š RÃ©sultats

| MÃ©trique | Valeur |
|----------|--------|
| **Test Accuracy** | 94.2% |
| **Test Loss** | 0.045 |
| **Precision (Helmet)** | 87% |
| **Recall (Helmet)** | 84% |
| **F1-Score** | 0.855 |
| **Phase 1 Training Time** | ~30 secondes |
| **Phase 2 Training Time** | ~2 minutes |
| **Total Training Time** | **~3 minutes** |

### ğŸ“ˆ Courbes d'EntraÃ®nement

Les courbes montrent :
- **Phase 1** : Convergence rapide avec couches gelÃ©es
- **Phase 2** : AmÃ©lioration progressive avec fine-tuning
- **Pas d'overfitting** : Val_loss suit train_loss de prÃ¨s

### ğŸ¯ Matrice de Confusion

```
                 PrÃ©dit Helmet  PrÃ©dit No Helmet
Vrai Helmet           42              8
Vrai No Helmet         6             44
```

---

## ğŸ—ï¸ Architecture

```
Input Image (224Ã—224Ã—3)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MobileNetV2 [PrÃ©-entraÃ®nÃ©]        â”‚
â”‚  - 250 couches                      â”‚
â”‚  - 2.3M paramÃ¨tres                  â”‚
â”‚  - GelÃ© en Phase 1                  â”‚
â”‚  - Partiellement dÃ©gelÃ© en Phase 2  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
GlobalAveragePooling2D
(7Ã—7Ã—1280) â†’ (1280)
        â†“
Dense(256) + ReLU + Dropout(0.5)
        â†“
Dense(2) + Softmax
        â†“
Output: [P(Helmet), P(No Helmet)]
```

### ğŸ”§ SpÃ©cifications

- **ModÃ¨le de base** : MobileNetV2
- **PrÃ©-entraÃ®nement** : ImageNet (14M images)
- **Input Size** : 224Ã—224 pixels (RGB)
- **Nombre de classes** : 2
- **Total ParamÃ¨tres** : 2.3M
- **ParamÃ¨tres entraÃ®nables** : ~5K (Phase 1), ~600K (Phase 2)

---

## ğŸ“‚ Structure du Projet

```
helmet-detection-transfer-learning/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                      # Documentation
â”œâ”€â”€ ğŸ“„ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ .gitignore                     # Fichiers Ã  ignorer
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ dataset/
â”‚       â”œâ”€â”€ train/                    # Images d'entraÃ®nement (60%)
â”‚       â”‚   â”œâ”€â”€ helmet/
â”‚       â”‚   â””â”€â”€ no_helmet/
â”‚       â”œâ”€â”€ val/                      # Images de validation (20%)
â”‚       â”‚   â”œâ”€â”€ helmet/
â”‚       â”‚   â””â”€â”€ no_helmet/
â”‚       â””â”€â”€ test/                     # Images de test (20%)
â”‚           â”œâ”€â”€ helmet/
â”‚           â””â”€â”€ no_helmet/
â”‚
â”œâ”€â”€ ğŸ“ models/                        # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ model_phase1.h5              # ModÃ¨le aprÃ¨s Phase 1
â”‚   â””â”€â”€ model_final.h5               # ModÃ¨le final (Phase 1 + Phase 2)
â”‚
â”œâ”€â”€ ğŸ“ results/                       # RÃ©sultats et visualisations
â”‚   â”œâ”€â”€ training_curves.png          # Courbes Loss/Accuracy
â”‚   â”œâ”€â”€ confusion_matrix.png         # Matrice de confusion
â”‚   â””â”€â”€ metrics.txt                  # RÃ©sultats chiffrÃ©s
â”‚
â”œâ”€â”€ ğŸ train.py                       # Script d'entraÃ®nement (Phase 1 & 2)
â””â”€â”€ ğŸ evaluate.py                    # Script d'Ã©valuation
```

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.9+
- pip (gestionnaire de paquets Python)
- ~2GB d'espace disque (pour les modÃ¨les et donnÃ©es)

### Ã‰tapes

#### 1ï¸âƒ£ Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/AkramNejj33/Helmet-Detection-with-Transfer-Learning.git
```

#### 2ï¸âƒ£ CrÃ©er un environnement virtuel

**Sur macOS / Linux** :
```bash
python -m venv venv
source venv/bin/activate
```

**Sur Windows (PowerShell)** :
```bash
python -m venv venv
venv\Scripts\Activate.ps1
```

#### 3ï¸âƒ£ Installer les dÃ©pendances

```bash
pip install --upgrade pip
pip install -r requirements.txt
```


#### 4ï¸âƒ£ TÃ©lÃ©charger et organiser les donnÃ©es

TÃ©lÃ©charge le dataset depuis [Kaggle](https://www.kaggle.com/datasets/meliodassourav/traffic-violation-dataset-v3?resource=download)

Organise les images dans la structure :
```
data/dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ helmet/
â”‚   â””â”€â”€ no_helmet/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ helmet/
â”‚   â””â”€â”€ no_helmet/
â””â”€â”€ test/
    â”œâ”€â”€ helmet/
    â””â”€â”€ no_helmet/
```

---

## ğŸ¯ Utilisation

### EntraÃ®ner le modÃ¨le

```bash
python train.py
```

**Sortie** :
- `model_phase1.h5` (modÃ¨le aprÃ¨s Phase 1)
- `model_final.h5` (modÃ¨le final)
- `training_curves.png` (courbes d'entraÃ®nement)

### Ã‰valuer le modÃ¨le

```bash
python evaluate.py
```

**Sortie** :
- MÃ©triques (Accuracy, Loss, Precision, Recall, F1-Score)
- `confusion_matrix.png` (matrice de confusion)

## ğŸ“š Concepts ClÃ©s

### Transfer Learning

**DÃ©finition** : RÃ©utiliser les features apprises sur une grande base de donnÃ©es (ImageNet) pour rÃ©soudre une nouvelle tÃ¢che avec moins de donnÃ©es et de temps.

**Avantages** :
- âœ… Convergence 10x plus rapide
- âœ… Moins de donnÃ©es requises
- âœ… Meilleure performance
- âœ… RÃ©duction du coÃ»t computationnel

### Phase 1 : Feature Extraction

- **Backbone MobileNetV2** : â„ï¸ GelÃ© (poids ne changent pas)
- **Nouvelles couches** : ğŸ”¥ EntraÃ®nÃ©es
- **Learning rate** : 1e-4
- **Epochs** : 10
- **RÃ©sultat** : Accuracy ~88%

### Phase 2 : Fine-Tuning

- **Backbone couches 1-220** : â„ï¸ GelÃ©es
- **Backbone couches 221-250** : ğŸ”¥ DÃ©gelÃ©es
- **Nouvelles couches** : ğŸ”¥ EntraÃ®nÃ©es
- **Learning rate** : 1e-5 (10x plus faible)
- **Epochs** : 10
- **RÃ©sultat** : Accuracy ~94%

### Data Augmentation

Transformations alÃ©atoires appliquÃ©es Ã  chaque epoch :
- Rotation : Â±30Â°
- DÃ©calage : Â±20%
- Zoom : 80-120%
- Retournement horizontal

**Effet** : Dataset augmentÃ© virtuellement â†’ moins d'overfitting

### Dropout

- Ã‰teint alÃ©atoirement 50% des neurones pendant l'entraÃ®nement
- Force le modÃ¨le Ã  Ãªtre robuste
- RÃ©duit l'overfitting

---

## ğŸ“Š Comparaison : Transfer Learning vs CNN from Scratch

| CritÃ¨re | Transfer Learning | CNN from Scratch |
|---------|------------------|------------------|
| **Images requises** | 5,000 | 100,000+ |
| **Temps d'entraÃ®nement** | 3 minutes | 10+ heures |
| **Accuracy** | 94% | 75-80% |
| **GPU requis** | Non (CPU ok) | Oui (recommandÃ©) |
| **Production** | âœ… ImmÃ©diat | âŒ Trop lent |

---

## ğŸ“– DÃ©pendances

```
tensorflow==2.14.0        # Framework d'IA
keras==2.14.0            # API de haut niveau
numpy==1.24.3            # Calcul numÃ©rique
matplotlib==3.7.2        # Visualisation
scikit-learn==1.3.0      # MÃ©triques
seaborn==0.12.2          # Visualisation avancÃ©e
pillow==10.0.0           # Traitement d'images
```

Pour installer automatiquement :
```bash
pip install -r requirements.txt
```

---

## ğŸ” Dataset

### Source

[Traffic Violation Dataset V3 - Kaggle](https://www.kaggle.com/datasets/meliodassourav/traffic-violation-dataset-v3?resource=download)

### CaractÃ©ristiques

- **Nombre d'images** : 5,000+
- **Classes** : Helmet / No Helmet
- **Format** : JPEG
- **RÃ©solution** : VariÃ©e (redimensionnÃ©e Ã  224Ã—224)
- **RÃ©partition** : Train (60%) / Val (20%) / Test (20%)

### Statistiques

```
Dataset Statistics:
â”œâ”€â”€ Train Set: 3,000 images
â”‚   â”œâ”€â”€ Helmet: 1,500 images
â”‚   â””â”€â”€ No Helmet: 1,500 images
â”œâ”€â”€ Val Set: 500 images
â”‚   â”œâ”€â”€ Helmet: 250 images
â”‚   â””â”€â”€ No Helmet: 250 images
â””â”€â”€ Test Set: 500 images
    â”œâ”€â”€ Helmet: 250 images
    â””â”€â”€ No Helmet: 250 images
```

---

## ğŸ“ Explications DÃ©taillÃ©es

### Pourquoi MobileNetV2 ?

| CritÃ¨re | MobileNetV2 | ResNet50 | VGG16 |
|---------|-------------|----------|-------|
| ParamÃ¨tres | 3.5M | 25.5M | 138M |
| Vitesse | âš¡âš¡âš¡ | âš¡âš¡ | âš¡ |
| Accuracy ImageNet | 92% | 94% | 90% |
| Production | âœ… | âš ï¸ | âŒ |

**Choix** : MobileNetV2 est le meilleur compromis entre lÃ©gÃ¨retÃ©, rapiditÃ© et performance.

### Pourquoi 224Ã—224 pixels ?

C'est la taille standard sur laquelle MobileNetV2 a Ã©tÃ© prÃ©-entraÃ®nÃ©. C'est un compromis optimal :
- Assez grand pour voir les dÃ©tails
- Assez petit pour Ãªtre rapide

### Pourquoi Softmax et pas Sigmoid ?

- **Softmax** : Pour multi-classe mutuellement exclusif (soit Helmet, soit No Helmet)
- **Sigmoid** : Pour multi-label (une image peut avoir plusieurs labels)

Notre cas = **Softmax**

### Comment fonctionne le Dropout ?

**Pendant l'entraÃ®nement** :
- 50% des neurones sont Ã©teints alÃ©atoirement
- Le modÃ¨le apprend Ã  Ãªtre robuste sans dÃ©pendre d'une seule voie

**Pendant l'infÃ©rence** :
- Tous les neurones sont actifs
- Leurs sorties sont rÃ©duites de 50%

---

## ğŸ“ˆ MÃ©triques ExpliquÃ©es

### Accuracy
```
Accuracy = PrÃ©dictions correctes / Total de prÃ©dictions
= (TP + TN) / (TP + TN + FP + FN)
```

### Precision
```
Precision = TP / (TP + FP)
RÃ©ponse Ã  : Sur tous les "Helmet" prÃ©dits, combien Ã©taient corrects ?
```

### Recall
```
Recall = TP / (TP + FN)
RÃ©ponse Ã  : Sur tous les vrais "Helmet", combien avons-nous dÃ©tectÃ© ?
```

### F1-Score
```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
Moyenne harmonique de Precision et Recall
```

---

## ğŸš¨ DÃ©pannage

### ProblÃ¨me : "OSError: [WinError 5] AccÃ¨s refusÃ©"

**Solution** : ExÃ©cuter PowerShell en tant qu'administrateur
```bash
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
venv\Scripts\Activate.ps1
```

### ProblÃ¨me : "No module named 'tensorflow'"

**Solution** : VÃ©rifier que l'environnement est activÃ©
```bash
which python  # ou where python sur Windows
```

Le chemin doit contenir `venv`.

### ProblÃ¨me : Installation TensorFlow trÃ¨s lente

**Solution** : Utiliser la version CPU
```bash
pip install tensorflow-cpu==2.14.0
```

### ProblÃ¨me : "FileNotFoundError: data/dataset not found"

**Solution** : Organiser les donnÃ©es dans la structure correcte
```
data/dataset/train/helmet/
data/dataset/train/no_helmet/
data/dataset/val/helmet/
data/dataset/val/no_helmet/
data/dataset/test/helmet/
data/dataset/test/no_helmet/
```

---

## ğŸ“š AmÃ©liorations Futures

- [ ] ImplÃ©menter YOLO pour dÃ©tection spatiale (bounding box)
- [ ] Optimiser pour infÃ©rence mobile (TensorFlow Lite)
- [ ] Ajouter une API REST pour dÃ©ploiement en production
- [ ] CrÃ©er une application web (Streamlit/Flask)
- [ ] Augmenter la diversitÃ© du dataset
- [ ] ImplÃ©menter la dÃ©tection vidÃ©o en temps rÃ©el

---

## ğŸ”— Ressources & RÃ©fÃ©rences

- [MobileNetV2 Paper](https://arxiv.org/abs/1801.04381)
- [ImageNet Dataset](http://www.image-net.org/)
- [TensorFlow Documentation](https://tensorflow.org/)
- [Kaggle Dataset](https://www.kaggle.com/datasets/meliodassourav/traffic-violation-dataset-v3)
- [Transfer Learning Guide](https://cs231n.github.io/transfer-learning/)

---

## ğŸ“„ Licence

Ce projet est sous licence **MIT**. Voir le fichier `LICENSE` pour plus de dÃ©tails.

---

## ğŸ‘¤ Auteur

**[Mohammed Akram Nejjari]**
- ğŸ“§ Email : [akramnejjari726@gmail.com]
- ğŸ”— GitHub : [AkramNejj33]
- ğŸ’¼ LinkedIn : [Mohammed Akram Nejjari]

---

## ğŸ™ Remerciements

- **Kaggle** pour le dataset
- **Google** pour MobileNetV2 et TensorFlow
- **CommunautÃ© IA** pour les ressources et tutoriels

---

<div align="center">

**Made with â¤ï¸ for Computer Vision & Transfer Learning**


</div>
